{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Extraction with layout and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer\n",
    "import os \n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import fitz\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(file_path): #function to extract text using tesseract\n",
    "    try:\n",
    "        text = ''\n",
    "\n",
    "        ## add your own file_location to tesseract.exe\n",
    "        pytesseract.pytesseract.tesseract_cmd = r'C:/imls-research-grant/pr_files/tesseract/tesseract.exe'\n",
    "\n",
    "\n",
    "        ## add your own file_location to poppler\n",
    "        images = convert_from_path(pdf_path=file_path+'.pdf',poppler_path = 'C:\\imls-research-grant\\pr_files\\poppler')\n",
    "        for count, img in enumerate(images):\n",
    "            extracted_text = pytesseract.image_to_string(img)\n",
    "            text += extracted_text\n",
    "            \n",
    "            # adding this text for line break  \n",
    "            text += '****************************************************************************************************'\n",
    "        \n",
    "        \n",
    "        return text\n",
    "    except:\n",
    "        return 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path): # function to extract text using pdfminer\n",
    "    try:\n",
    "        text = ''\n",
    "        title = ''\n",
    "        layout = ''\n",
    "        for page_layout in extract_pages(file_path+'.pdf'):\n",
    "            for element in page_layout:\n",
    "\n",
    "                if isinstance(element, LTTextContainer):\n",
    "                    for text_line in element:\n",
    "                        try:\n",
    "                            text += text_line.get_text()\n",
    "                        except:\n",
    "                            continue\n",
    "                        \n",
    "            if len(text) != 0:  \n",
    "                \n",
    "                # adding this text for line break                 \n",
    "                text += '****************************************************************************************************'\n",
    "        \n",
    "        with open(file_path+'.pdf', 'rb') as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            try:\n",
    "                title = reader.metadata['/Title']\n",
    "            except:\n",
    "                title = 'NA'\n",
    "        with fitz.open(file_path+'.pdf') as doc:\n",
    "            layout = str(doc[0].rect.width)+' * '+str(doc[0].rect.height)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return text, title, layout\n",
    "    \n",
    "    \n",
    "    except:\n",
    "        return  0, title, layout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the below code we just iterating through each pdf available in directory \n",
    "# first we try to exract the text using the pdfminer\n",
    "# If pdfminer not works then we extract the text using tesseract\n",
    "# finnally we storing it to dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# give file location to both positive and negative data one after another\n",
    "p = os.listdir('C:\\imls-research-grant\\pr_files/2017\\data/full_pdf_data/1.Texas_Pub_Candidates')\n",
    "c = list()\n",
    "num = 20\n",
    "count = 0\n",
    "df = pd.DataFrame(columns = ['pdf_name', 'text', 'title', 'layout'])\n",
    "for k, i in enumerate(p[:]):\n",
    "    os.chdir('C:\\imls-research-grant\\pr_files/2017\\data/full_pdf_data/1.Texas_Pub_Candidates/'+i)\n",
    "    text, title, layout =  extract_text_from_pdf(i)\n",
    "    if text == 0 or text == '':\n",
    "        text =  ocr(i)\n",
    "        if text == 0 or text == '':\n",
    "            continue\n",
    "    # print(i, text, title, layout)\n",
    "    df.loc[len(df.index)] = [i, text, title, layout]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = list()\n",
    "total_chracter_l = list()\n",
    "total_words_l = list()\n",
    "total_lines_l = list()\n",
    "avg_words_page_l = list()\n",
    "avg_lines_page_l = list()\n",
    "space_char_per_l = list()\n",
    "avg_alphanum_per_l = list()\n",
    "line_ratio_l = list()\n",
    "total_upcase_page_l = list()\n",
    "total_alphnum_line_l = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           pdf_name  \\\n",
      "0  24LOI5BAD2PKTQ6SUMPFNGPTATFJCMBL   \n",
      "1  252QHHKHPARPIPSWWHPFC5MTWPS5TF42   \n",
      "\n",
      "                                                text  \\\n",
      "0  lt takes more than a kiss.\\n\\nP+ walelelTinial...   \n",
      "1  Acknowledgements\\nThis report was researched a...   \n",
      "\n",
      "                                             title         layout  \n",
      "0                             Vaccine Billboard Ad  792.0 * 360.0  \n",
      "1  Microsoft PowerPoint - ACS Chartbook 2006_FINAL  612.0 * 792.0   2 2 2 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#extracting structural faetures based above extracted text\n",
    "for text in df['text']:\n",
    "    page_count = 0\n",
    "    total_lines = 0\n",
    "    total_words = 0\n",
    "    total_chracter = 0\n",
    "    total_spaces = 0\n",
    "    total_alphnum_page = 0\n",
    "    total_upcase_page = 0\n",
    "    total_alphnum_line = 0\n",
    "    max = None\n",
    "    min = None\n",
    "    for page in text.split('****************************************************************************************************'):\n",
    "        num_lines_page = 0\n",
    "        num_words_page = 0\n",
    "        num_char_page = 0\n",
    "        num_spaces_page = 0\n",
    "        num_alphnum_page = 0\n",
    "        num_upcase_page = 0\n",
    "        num_alphnum_line = 0\n",
    "        if len(page) != 0 :\n",
    "            for line in page.split('\\n'):\n",
    "                if len(line) != 0 :\n",
    "                    #print(len(line.split(\" \")))\n",
    "                    m = line.split(\" \")\n",
    "                    if(line[0].isupper()):\n",
    "                        num_upcase_page += 1\n",
    "                        \n",
    "                    num_spaces_page += len(m)-1\n",
    "                    num_char_page += len(line)\n",
    "                    num_words_page += len(m)\n",
    "                    num_lines_page += 1\n",
    "                    \n",
    "                    if max==None and min == None:\n",
    "                        max = len(line)\n",
    "                        min = len(line)\n",
    "                    if len(line) > max:\n",
    "                        max = len(line)\n",
    "                    if len(line) < min:\n",
    "                        min = len(line)\n",
    "                        \n",
    "                    for i in m:\n",
    "                        if(i.isalpha() or i.isnumeric()):\n",
    "                            continue\n",
    "                        else:\n",
    "                            if(i.isalnum()):\n",
    "                                num_alphnum_page += 1\n",
    "                                \n",
    "                    if(line[0].isalpha() or line[0].isnumeric()):\n",
    "                            continue\n",
    "                    else:\n",
    "                        if(line[0].isalnum()):\n",
    "                            num_alphnum_line += 1\n",
    "            page_count += 1\n",
    "                                \n",
    "            total_alphnum_line += num_alphnum_line\n",
    "            total_upcase_page += num_upcase_page\n",
    "            total_alphnum_page += num_alphnum_page\n",
    "            total_lines += num_lines_page\n",
    "            total_words += num_words_page\n",
    "            total_chracter += num_char_page\n",
    "            total_spaces += num_spaces_page\n",
    "    try:\n",
    "        avg_lines_page = total_lines/page_count\n",
    "        avg_words_page = total_words/page_count\n",
    "        space_char_per = round((total_spaces / total_chracter) * 100, 2)\n",
    "        avg_alphanum_per = (total_alphnum_page / total_words) * 100\n",
    "        line_ratio  = min/max\n",
    "    except:\n",
    "        total_chracter_l.append(0)\n",
    "        total_words_l.append(0)\n",
    "        total_lines_l.append(0)\n",
    "        avg_words_page_l.append(0)\n",
    "        avg_lines_page_l.append(0)\n",
    "        space_char_per_l.append(0)\n",
    "        avg_alphanum_per_l.append(0)\n",
    "        line_ratio_l.append(0)\n",
    "        total_upcase_page_l.append(0)\n",
    "        total_alphnum_line_l.append(0)\n",
    "    total_chracter_l.append(total_chracter)\n",
    "    total_words_l.append(total_words)\n",
    "    total_lines_l.append(total_lines)\n",
    "    avg_words_page_l.append(avg_words_page)\n",
    "    avg_lines_page_l.append(avg_lines_page)\n",
    "    space_char_per_l.append(space_char_per)\n",
    "    avg_alphanum_per_l.append(avg_alphanum_per)\n",
    "    line_ratio_l.append(line_ratio)\n",
    "    total_upcase_page_l.append(total_upcase_page)\n",
    "    total_alphnum_line_l.append(total_alphnum_line)\n",
    "     \n",
    "df[\"total_chracter\"] = total_chracter_l\n",
    "df[\"total_words\"] = total_words_l\n",
    "df[\"total_lines\"] = total_lines_l\n",
    "df[\"avg_words_page\"] = avg_words_page_l\n",
    "df[\"avg_lines_page\"] = avg_lines_page_l\n",
    "df[\"space_char_per\"] = space_char_per_l\n",
    "df[\"avg_alphanum_per\"] = avg_alphanum_per_l\n",
    "df[\"line_ratio\"] = line_ratio_l\n",
    "df[\"total_upcase_page\"] = total_upcase_page_l\n",
    "df[\"total_alphnum_line\"] = total_alphnum_line_l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('s_p.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
